{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install kaggle\n",
    "#!mkdir ~/.kaggle\n",
    "#!cp kaggle.json ~/.kaggle/\n",
    "#!kaggle datasets download -d puneet6060/intel-image-classification\n",
    "!unzip -o intel-image-classification.zip &> /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "!mkdir seg_val && mv seg_test/seg_test/** seg_val/ && rm -rf seg_test**\n",
    "!mkdir seg_test && mv seg_pred/seg_pred/** seg_test/ && rm -rf seg_pred**\n",
    "!mv seg_train/seg_train/** seg_train/ && rm -rf seg_train/seg_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# fileList = glob.glob('seg_**/**/*.jpg', recursive=True)\n",
    "# for file in fileList:\n",
    "#     if len(os.path.basename(file)) > 6:\n",
    "#         os.remove(file)\n",
    "\n",
    "# folders = ['seg_train', 'seg_val']\n",
    "# for folder in folders:\n",
    "#     for dir in os.listdir(folder):\n",
    "#         i = 0\n",
    "#         files = sorted(os.listdir(os.path.join(folder, dir)))\n",
    "#         for file in sorted(os.listdir(os.path.join(folder, dir))):\n",
    "#             if i > 10 and len(files) > 20:\n",
    "#                 os.remove(os.path.join(os.path.join(folder, dir), file))\n",
    "#             i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from layers.Activation import Activation, SoftmaxActivation, ReluActivation\n",
    "from layers.Conv2D import Conv2D\n",
    "from layers.ConvNeuralNetwork import NeuralNetwork\n",
    "from layers.Dense import Dense\n",
    "from layers.Flatten import Flatten\n",
    "from layers.Pooling import MaxPooling2D\n",
    "from layers.utils import AdamOptimizer, CrossEntropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dir = './seg_train'\n",
    "val_dir = './seg_val'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = [train_ds.take(1)]\n",
    "images[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rescale = tf.keras.layers.Rescaling(1. / 255)\n",
    "train_ds = train_ds.map(lambda x, y: (rescale(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (rescale(x), y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_batch, labels_batch = next(iter(train_ds))\n",
    "first_image = image_batch[0]\n",
    "print(\"Min and max values after rescaling:\", np.min(first_image), np.max(first_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_processed_input(dataset):\n",
    "    X = []\n",
    "    y = []\n",
    "    for image_batch, label_batch in dataset:\n",
    "        for i in range(BATCH_SIZE):\n",
    "            if i < image_batch.shape[0]:\n",
    "                X.append(image_batch[i].numpy())\n",
    "                y.append(label_batch[i].numpy())\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    X = np.moveaxis(X, -1, 1)\n",
    "    y = to_categorical(y.astype(\"int\"))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_train, y_train = get_processed_input(train_ds)\n",
    "X_val, y_val = get_processed_input(train_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MAX_SIZE = 50\n",
    "X_train = np.array(X_train)[:MAX_SIZE]\n",
    "y_train = np.array(y_train)[:MAX_SIZE]\n",
    "print(\"Shape of X_train, y_train:\", X_train.shape, y_train.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DeepLearningModel:\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs, val_data):\n",
    "        model = NeuralNetwork(optimizer=AdamOptimizer(), loss=CrossEntropy, val_data=val_data)\n",
    "        model.add(Conv2D(input_shape=n_inputs, n_filters=16, filter_shape=(2, 2), stride=1, padding='same'))\n",
    "        # model.add(BatchNormalization(axis=0))\n",
    "        model.add(Activation(ReluActivation))\n",
    "        model.add(MaxPooling2D(pool_shape=(2, 2), stride=2, padding='same'))\n",
    "\n",
    "        model.add(Conv2D(n_filters=32, filter_shape=(2, 2), stride=1, padding='same'))\n",
    "        # model.add(BatchNormalization(axis=0))\n",
    "        model.add(Activation(ReluActivation))\n",
    "        model.add(MaxPooling2D(pool_shape=(2, 2)))  # Valid padding\n",
    "\n",
    "        model.add(Conv2D(n_filters=64, filter_shape=(2, 2), stride=1, padding='same'))\n",
    "        # model.add(BatchNormalization(axis=0))\n",
    "        model.add(Activation(ReluActivation))\n",
    "        model.add(MaxPooling2D(pool_shape=(2, 2)))  # Valid padding\n",
    "\n",
    "        model.add(Conv2D(n_filters=128, filter_shape=(2, 2), stride=1, padding='same'))\n",
    "        # model.add(BatchNormalization(axis=0))\n",
    "        model.add(Activation(ReluActivation))\n",
    "        model.add(MaxPooling2D(pool_shape=(2, 2)))  # Valid padding\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256))\n",
    "        # model.add(BatchNormalization())\n",
    "        model.add(Activation(ReluActivation))\n",
    "\n",
    "        model.add(Dense(256))\n",
    "        # model.add(BatchNormalization())\n",
    "        model.add(Activation(ReluActivation))\n",
    "\n",
    "        model.add(Dense(n_outputs))\n",
    "        model.add(Activation(SoftmaxActivation))\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model = DeepLearningModel(n_inputs=(3, 154, 154), n_outputs=6, val_data=(X_val, y_val)).get_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "train_err, val_err = model.fit(X_train, y_train, n_epochs=5, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training and validation error plot\n",
    "n = len(train_err)\n",
    "training, = plt.plot(range(n), train_err, label=\"Training Error\")\n",
    "validation, = plt.plot(range(n), val_err, label=\"Validation Error\")\n",
    "plt.legend(handles=[training, validation])\n",
    "plt.title(\"Error Plot\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train, y_train: (500, 3, 224, 224) (500, 6)\n"
     ]
    }
   ],
   "source": [
    "MAX_SIZE = 50\n",
    "X_train = np.array(X_train)[:MAX_SIZE]\n",
    "y_train = np.array(y_train)[:MAX_SIZE]\n",
    "print(\"Shape of X_train, y_train:\", X_train.shape, y_train.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class DeepLearningModel:\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs, val_data):\n",
    "        model = NeuralNetwork(optimizer=AdamOptimizer(), loss=CrossEntropy, val_data=val_data)\n",
    "        model.add(Conv2D(input_shape=n_inputs, n_filters=16, filter_shape=(2, 2), stride=1, padding='same'))\n",
    "        # model.add(BatchNormalization(axis=0))\n",
    "        model.add(Activation(ReluActivation))\n",
    "        model.add(MaxPooling2D(pool_shape=(2, 2), stride=2, padding='same'))\n",
    "\n",
    "        model.add(Conv2D(n_filters=32, filter_shape=(2, 2), stride=1, padding='same'))\n",
    "        # model.add(BatchNormalization(axis=0))\n",
    "        model.add(Activation(ReluActivation))\n",
    "        model.add(MaxPooling2D(pool_shape=(2, 2)))  # Valid padding\n",
    "\n",
    "        model.add(Conv2D(n_filters=64, filter_shape=(2, 2), stride=1, padding='same'))\n",
    "        # model.add(BatchNormalization(axis=0))\n",
    "        model.add(Activation(ReluActivation))\n",
    "        model.add(MaxPooling2D(pool_shape=(2, 2)))  # Valid padding\n",
    "\n",
    "        model.add(Conv2D(n_filters=128, filter_shape=(2, 2), stride=1, padding='same'))\n",
    "        # model.add(BatchNormalization(axis=0))\n",
    "        model.add(Activation(ReluActivation))\n",
    "        model.add(MaxPooling2D(pool_shape=(2, 2)))  # Valid padding\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256))\n",
    "        # model.add(BatchNormalization())\n",
    "        model.add(Activation(ReluActivation))\n",
    "\n",
    "        model.add(Dense(256))\n",
    "        # model.add(BatchNormalization())\n",
    "        model.add(Activation(ReluActivation))\n",
    "\n",
    "        model.add(Dense(n_outputs))\n",
    "        model.add(Activation(SoftmaxActivation))\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model = DeepLearningModel(n_inputs=(3, 154, 154), n_outputs=6, val_data=(X_val, y_val)).get_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "train_err, val_err = model.fit(X_train, y_train, n_epochs=5, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training and validation error plot\n",
    "n = len(train_err)\n",
    "training, = plt.plot(range(n), train_err, label=\"Training Error\")\n",
    "validation, = plt.plot(range(n), val_err, label=\"Validation Error\")\n",
    "plt.legend(handles=[training, validation])\n",
    "plt.title(\"Error Plot\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}